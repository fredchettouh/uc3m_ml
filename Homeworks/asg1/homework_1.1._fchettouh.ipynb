{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgTfb2tWZz_L"
   },
   "source": [
    "## Homework I: Frederik Chettouh\n",
    "\n",
    "I have created a new notebook for easier readibility and to write where possible code from scratch with help from the Udacity \"Intro to Deeplearning with Pytorch\" course and class material.\n",
    "\n",
    "## Part I: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4jmbS0b7ZUTv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1584969670833,
     "user": {
      "displayName": "Fred Che",
      "photoUrl": "",
      "userId": "07612464138287230381"
     },
     "user_tz": -60
    },
    "id": "Fg1xZbQCZUT0",
    "outputId": "f76ece3f-bc7b-49e4-e532-d4009a9b3623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11fe89fa0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#getting the data\n",
    "torch.manual_seed(0)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,),(0.5,))]\n",
    "                              )\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "# checking out one batch\n",
    "dataiter = iter(trainloader)\n",
    "images,labels = dataiter.next()\n",
    "# squeeze reshapes the nupy array \n",
    "plt.imshow(images[0].numpy().squeeze(),cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wnlc37zCZUT6"
   },
   "source": [
    "## Part II: Single layer Multiclass Neural Network\n",
    "\n",
    "Next two classes are defined, the first is the network, the second is an extension that trains and validates the network automatically and produces the output. There is no seperate test and validation set since this is part of the second homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape[-1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NpT1jT8ZUT3"
   },
   "outputs": [],
   "source": [
    "# setting the shape of the vector\n",
    "input_shape = images.shape[-1]**2\n",
    "hidden_shape_1 = 128\n",
    "hidden_shape_2 = 64\n",
    "output_shape = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDKqJQ3rZUT7"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Single_LR(nn.Module):\n",
    "    def __init__(self,dimx, labels):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(dimx, labels)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        print(x.shape)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        print(x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = self.logsoftmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vV9mCFeZUT-"
   },
   "outputs": [],
   "source": [
    "class Single_LR_extended(Single_LR):\n",
    "    \n",
    "    def __init__(self,dimx,nlabels,epochs=5,lr=0.001):\n",
    "        \n",
    "        super().__init__(dimx,nlabels)  \n",
    "        \n",
    "        self.lr = lr \n",
    "        \n",
    "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.criterion = nn.NLLLoss()               \n",
    "        \n",
    "        self.loss_during_training = []\n",
    "        self.validate_loss = []\n",
    "        self.accuracy = []\n",
    "        \n",
    "    def validate(self,testloader):\n",
    "        self.eval()\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for images,labels in testloader:\n",
    "              log_proba = self.forward(images)\n",
    "              loss = self.criterion(log_proba, labels)\n",
    "              test_loss += loss\n",
    "\n",
    "              proba = torch.exp(log_proba)\n",
    "              top_p, top_c = proba.topk(1, dim=1)\n",
    "              equals = top_c ==labels.view(*top_c.shape)\n",
    "              accuracy +=torch.mean(equals.type(torch.FloatTensor))    \n",
    "            else:\n",
    "              self.validate_loss.append(test_loss/len(testloader))\n",
    "              self.accuracy.append(accuracy/len(testloader))\n",
    "                    \n",
    "              print(\"Validation loss: {}\" .format(self.validate_loss[-1]))\n",
    "              print(\"Accuracy in val set : {}\" .format(self.accuracy[-1]))\n",
    "                    \n",
    "        \n",
    "    def train_loop(self,trainloader,testloader = None):\n",
    "      self.train()\n",
    "      for e in range(int(self.epochs)):\n",
    "            \n",
    "        running_loss = 0.\n",
    "            \n",
    "        for images, labels in trainloader:            \n",
    "          self.optim.zero_grad()\n",
    "\n",
    "          out = self.forward(images)\n",
    "                \n",
    "          loss = self.criterion(out, labels)\n",
    "          running_loss += loss.item()\n",
    "\n",
    "          loss.backward()\n",
    "          self.optim.step() \n",
    "                \n",
    "        else:\n",
    "          self.loss_during_training.append(running_loss/len(trainloader))\n",
    "                \n",
    "          print(\"Training loss after {} epochs: {}\" .format(e+1,self.loss_during_training[-1]))\n",
    "                \n",
    "          if testloader:\n",
    "            self.validate(testloader)\n",
    "            self.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmLTzTPYZUUB"
   },
   "outputs": [],
   "source": [
    "single_model = Single_LR_extended(input_shape,output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1584970158917,
     "user": {
      "displayName": "Fred Che",
      "photoUrl": "",
      "userId": "07612464138287230381"
     },
     "user_tz": -60
    },
    "id": "-x-xKjoH4i6e",
    "outputId": "eff55f5d-a7fd-48c8-f774-3b72e6794e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single_LR_extended(\n",
      "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (logsoftmax): LogSoftmax()\n",
      "  (criterion): NLLLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(single_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49670,
     "status": "ok",
     "timestamp": 1584970210214,
     "user": {
      "displayName": "Fred Che",
      "photoUrl": "",
      "userId": "07612464138287230381"
     },
     "user_tz": -60
    },
    "id": "-gI2D3IhZUUE",
    "outputId": "567ae8ac-b674-4380-bc92-555ae46594b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 784])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cfbb733cc5d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msingle_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-d26770a6f600>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, trainloader, testloader)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/University/UC3M/TFM/cnp_repo/neural-processes/tfm/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "single_model.train_loop(trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtlSQAEgZUUH"
   },
   "source": [
    "## Part III: Multiclass Multilayer perceptron\n",
    "\n",
    "Next we create a multilayer multiclass peceptron and an extended class that trains and validates the model automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09ZJ9HIEZUUH"
   },
   "outputs": [],
   "source": [
    "class Multi_LR(nn.Module):\n",
    "            \n",
    "    def __init__(self,input_shape,hidden_shape_1,hidden_shape_2,output_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(input_shape,hidden_shape_1)\n",
    "        self.fc2 = nn.Linear(hidden_shape_1,hidden_shape_2)\n",
    "        self.fc3 = nn.Linear(hidden_shape_2,output_shape)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        output = self.softmax(x)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5FJ4JY1ZUUO"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Multi_LR_extended(Multi_LR):\n",
    "    \n",
    "    def __init__(self,input_shape,hidden_shape_1,hidden_shape_2,output_shape,epochs=100,lr=0.001):\n",
    "        \n",
    "        super().__init__(input_shape,hidden_shape_1,hidden_shape_2,output_shape)  \n",
    "        self.lr = lr \n",
    "        \n",
    "        self.optim = optim.Adam(self.parameters(), self.lr)\n",
    "\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.criterion = nn.NLLLoss()            \n",
    "        \n",
    "        self.loss_during_training = [] \n",
    "        self.validate_loss = []\n",
    "        self.accuracy = []\n",
    "        \n",
    "        \n",
    "    def validate(self,testloader):\n",
    "        self.eval()\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for images,labels in testloader:\n",
    "                log_proba = self.forward(images)\n",
    "                loss = self.criterion(log_proba, labels)\n",
    "                test_loss +=loss\n",
    "\n",
    "                proba = torch.exp(log_proba)\n",
    "                top_p, top_c = proba.topk(1, dim=1)\n",
    "                equals = top_c ==labels.view(*top_c.shape)\n",
    "                accuracy +=torch.mean(equals.type(torch.FloatTensor))\n",
    "            else:\n",
    "                self.validate_loss.append(test_loss/len(testloader))\n",
    "                self.accuracy.append(accuracy/len(testloader))\n",
    "                    \n",
    "                print(\"Validation loss: {}\" .format(self.validate_loss[-1]))\n",
    "                print(\"Accuracy in val set : {}\" .format(self.accuracy[-1]))\n",
    "    def train_loop(self,trainloader,testloader = None):\n",
    "        self.train()\n",
    "        for e in range(int(self.epochs)):\n",
    "            \n",
    "            running_loss = 0.\n",
    "            \n",
    "            for images, labels in trainloader:            \n",
    "                self.optim.zero_grad()\n",
    "            \n",
    "                out = self.forward(images)\n",
    "                \n",
    "                loss = self.criterion(out, labels)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                self.optim.step() \n",
    "                \n",
    "            else:\n",
    "                self.loss_during_training.append(running_loss/len(trainloader))\n",
    "    \n",
    "                \n",
    "                print(\"Training loss after {} epochs: {}\" \n",
    "                      .format(e+1,self.loss_during_training[-1]))\n",
    "                \n",
    "                if testloader:\n",
    "                    self.validate(testloader)\n",
    "                    self.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623266,
     "status": "ok",
     "timestamp": 1584970914991,
     "user": {
      "displayName": "Fred Che",
      "photoUrl": "",
      "userId": "07612464138287230381"
     },
     "user_tz": -60
    },
    "id": "EafTW_9nZUUQ",
    "outputId": "72644fae-7169-4549-f7a0-e3c43ed8510a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss after 1 epochs: 0.4030217383700266\n",
      "Validation loss: 0.22190171480178833\n",
      "Accuracy in val set : 0.9343152642250061\n",
      "Training loss after 2 epochs: 0.19687108712783183\n",
      "Validation loss: 0.18923348188400269\n",
      "Accuracy in val set : 0.9409832954406738\n",
      "Training loss after 3 epochs: 0.14412035800016193\n",
      "Validation loss: 0.12691812217235565\n",
      "Accuracy in val set : 0.9607881903648376\n",
      "Training loss after 4 epochs: 0.11825160501000564\n",
      "Validation loss: 0.11191949993371964\n",
      "Accuracy in val set : 0.9637739062309265\n",
      "Training loss after 5 epochs: 0.09841096233889293\n",
      "Validation loss: 0.10453886538743973\n",
      "Accuracy in val set : 0.9657643437385559\n",
      "Training loss after 6 epochs: 0.08837731935774912\n",
      "Validation loss: 0.09444412589073181\n",
      "Accuracy in val set : 0.9703423380851746\n",
      "Training loss after 7 epochs: 0.07398902246830806\n",
      "Validation loss: 0.10157252848148346\n",
      "Accuracy in val set : 0.9692476391792297\n",
      "Training loss after 8 epochs: 0.06838068429235199\n",
      "Validation loss: 0.09292428195476532\n",
      "Accuracy in val set : 0.9712380766868591\n",
      "Training loss after 9 epochs: 0.061907585491108565\n",
      "Validation loss: 0.09113394469022751\n",
      "Accuracy in val set : 0.9709395170211792\n",
      "Training loss after 10 epochs: 0.05575227645045367\n",
      "Validation loss: 0.10229478776454926\n",
      "Accuracy in val set : 0.9697452187538147\n",
      "Training loss after 11 epochs: 0.050810228007709554\n",
      "Validation loss: 0.09865497797727585\n",
      "Accuracy in val set : 0.9710389971733093\n",
      "Training loss after 12 epochs: 0.04765635784077488\n",
      "Validation loss: 0.09161914885044098\n",
      "Accuracy in val set : 0.9740246534347534\n",
      "Training loss after 13 epochs: 0.04425202590586649\n",
      "Validation loss: 0.1003497987985611\n",
      "Accuracy in val set : 0.971636176109314\n",
      "Training loss after 14 epochs: 0.0435619907305841\n",
      "Validation loss: 0.10016979277133942\n",
      "Accuracy in val set : 0.9725318551063538\n",
      "Training loss after 15 epochs: 0.039323775300213484\n",
      "Validation loss: 0.08386285603046417\n",
      "Accuracy in val set : 0.9773089289665222\n",
      "Training loss after 16 epochs: 0.03520296260480335\n",
      "Validation loss: 0.10350701212882996\n",
      "Accuracy in val set : 0.9712380766868591\n",
      "Training loss after 17 epochs: 0.037979271905836776\n",
      "Validation loss: 0.08787668496370316\n",
      "Accuracy in val set : 0.9739251732826233\n",
      "Training loss after 18 epochs: 0.03164954171026076\n",
      "Validation loss: 0.11095234006643295\n",
      "Accuracy in val set : 0.9722332954406738\n",
      "Training loss after 19 epochs: 0.031006820378486247\n",
      "Validation loss: 0.10803326219320297\n",
      "Accuracy in val set : 0.9706408977508545\n",
      "Training loss after 20 epochs: 0.031114117493051843\n",
      "Validation loss: 0.09646940976381302\n",
      "Accuracy in val set : 0.9744227528572083\n",
      "Training loss after 21 epochs: 0.02824944629269252\n",
      "Validation loss: 0.11872115731239319\n",
      "Accuracy in val set : 0.9704418778419495\n",
      "Training loss after 22 epochs: 0.030366942118422977\n",
      "Validation loss: 0.11010568588972092\n",
      "Accuracy in val set : 0.9752189517021179\n",
      "Training loss after 23 epochs: 0.02514858600308046\n",
      "Validation loss: 0.09254447370767593\n",
      "Accuracy in val set : 0.9784036874771118\n",
      "Training loss after 24 epochs: 0.024809589018646345\n",
      "Validation loss: 0.11210115998983383\n",
      "Accuracy in val set : 0.9724323153495789\n",
      "Training loss after 25 epochs: 0.024136085871894634\n",
      "Validation loss: 0.10973960906267166\n",
      "Accuracy in val set : 0.975119411945343\n",
      "Training loss after 26 epochs: 0.024664199731307665\n",
      "Validation loss: 0.11073029786348343\n",
      "Accuracy in val set : 0.9744227528572083\n",
      "Training loss after 27 epochs: 0.022869143429630322\n",
      "Validation loss: 0.10732251405715942\n",
      "Accuracy in val set : 0.9761146306991577\n",
      "Training loss after 28 epochs: 0.0228086115232207\n",
      "Validation loss: 0.11671876907348633\n",
      "Accuracy in val set : 0.9757165312767029\n",
      "Training loss after 29 epochs: 0.01861136545905464\n",
      "Validation loss: 0.1127411425113678\n",
      "Accuracy in val set : 0.974920392036438\n",
      "Training loss after 30 epochs: 0.018326351642373142\n",
      "Validation loss: 0.12421530485153198\n",
      "Accuracy in val set : 0.9724323153495789\n",
      "Training loss after 31 epochs: 0.019517425430377405\n",
      "Validation loss: 0.12900283932685852\n",
      "Accuracy in val set : 0.9726313948631287\n",
      "Training loss after 32 epochs: 0.026164780317018563\n",
      "Validation loss: 0.1181701123714447\n",
      "Accuracy in val set : 0.974920392036438\n",
      "Training loss after 33 epochs: 0.0179574494542689\n",
      "Validation loss: 0.10822916775941849\n",
      "Accuracy in val set : 0.9752189517021179\n",
      "Training loss after 34 epochs: 0.01690244730579793\n",
      "Validation loss: 0.12358861416578293\n",
      "Accuracy in val set : 0.9736266136169434\n",
      "Training loss after 35 epochs: 0.016649099692594604\n",
      "Validation loss: 0.13517992198467255\n",
      "Accuracy in val set : 0.9736266136169434\n",
      "Training loss after 36 epochs: 0.02079597374009116\n",
      "Validation loss: 0.13277392089366913\n",
      "Accuracy in val set : 0.9761146306991577\n",
      "Training loss after 37 epochs: 0.016877026489249346\n",
      "Validation loss: 0.11734087765216827\n",
      "Accuracy in val set : 0.9761146306991577\n",
      "Training loss after 38 epochs: 0.014841098104251146\n",
      "Validation loss: 0.12923869490623474\n",
      "Accuracy in val set : 0.9757165312767029\n",
      "Training loss after 39 epochs: 0.019787722132934935\n",
      "Validation loss: 0.14687210321426392\n",
      "Accuracy in val set : 0.9738256335258484\n",
      "Training loss after 40 epochs: 0.01594985759649779\n",
      "Validation loss: 0.1489597111940384\n",
      "Accuracy in val set : 0.9730294346809387\n",
      "Training loss after 41 epochs: 0.015337833212072747\n",
      "Validation loss: 0.16601456701755524\n",
      "Accuracy in val set : 0.9719347357749939\n",
      "Training loss after 42 epochs: 0.020664686350107132\n",
      "Validation loss: 0.12766388058662415\n",
      "Accuracy in val set : 0.9773089289665222\n",
      "Training loss after 43 epochs: 0.013676916927549868\n",
      "Validation loss: 0.12939178943634033\n",
      "Accuracy in val set : 0.9770103693008423\n",
      "Training loss after 44 epochs: 0.015295487013670195\n",
      "Validation loss: 0.130323588848114\n",
      "Accuracy in val set : 0.9783041477203369\n",
      "Training loss after 45 epochs: 0.017580409381322375\n",
      "Validation loss: 0.13515429198741913\n",
      "Accuracy in val set : 0.9762141704559326\n",
      "Training loss after 46 epochs: 0.014954350064001627\n",
      "Validation loss: 0.1525254100561142\n",
      "Accuracy in val set : 0.9743232727050781\n",
      "Training loss after 47 epochs: 0.01322683884896631\n",
      "Validation loss: 0.15233376622200012\n",
      "Accuracy in val set : 0.9750199317932129\n",
      "Training loss after 48 epochs: 0.01547576357034035\n",
      "Validation loss: 0.1453283429145813\n",
      "Accuracy in val set : 0.9758160710334778\n",
      "Training loss after 49 epochs: 0.014853849543340335\n",
      "Validation loss: 0.13326503336429596\n",
      "Accuracy in val set : 0.9766122698783875\n",
      "Training loss after 50 epochs: 0.012478560828512196\n",
      "Validation loss: 0.15474295616149902\n",
      "Accuracy in val set : 0.9753184914588928\n"
     ]
    }
   ],
   "source": [
    "my_LR = Multi_LR_extended(input_shape,hidden_shape_1,hidden_shape_2,output_shape,epochs=50,lr=1e-3)\n",
    "\n",
    "my_LR.train_loop(trainloader, testloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yewoabWZUUT"
   },
   "source": [
    "## Part IV: Saving the configurations\n",
    "\n",
    "Last we will save and load the model parameters and show there is will be a size mismatch if not also the hyperparameters are matched. Then we will re train also save the hyperparamters and show that this way everything works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvhagG9zZUUU"
   },
   "outputs": [],
   "source": [
    "torch.save(my_LR.state_dict(),'checkpoint.pth')\n",
    "state_dict = torch.load('checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 977497,
     "status": "error",
     "timestamp": 1583006398126,
     "user": {
      "displayName": "Fred Che",
      "photoUrl": "",
      "userId": "07612464138287230381"
     },
     "user_tz": -60
    },
    "id": "Qa1vCufFZUUW",
    "outputId": "4695405f-c0df-40bb-bb73-67350bbbf50b"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ee6b2d91247f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_LR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulti_LR_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_shape_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_shape_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_LR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Multi_LR_extended:\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([128, 784]) from checkpoint, the shape in current model is torch.Size([128, 500])."
     ]
    }
   ],
   "source": [
    "my_LR = Multi_LR_extended(500,hidden_shape_1,hidden_shape_2,output_shape,epochs=50,lr=1e-3)\n",
    "my_LR.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "go6ZfVHBZUUZ"
   },
   "outputs": [],
   "source": [
    "#retraining with only one epoch to get a model\n",
    "my_LR = Multi_LR_extended(input_shape,hidden_shape_1,hidden_shape_2,output_shape,epochs=1,lr=1e-3)\n",
    "my_LR.train(trainloader, testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcT2F4EEZUUc"
   },
   "outputs": [],
   "source": [
    "chekpoint = checkpoint = {\n",
    "    'input_size':input_shape,\n",
    "    'hidden_size_1':hidden_shape_1,\n",
    "    'hidden_size_2':hidden_shape_2,\n",
    "    'ouput_size':output_shape,\n",
    "    'lr':1e-3,\n",
    "    'epochs':50,\n",
    "    'state_dict':my_LR.state_dict(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxzxqsp8ZUUg"
   },
   "outputs": [],
   "source": [
    "torch.save(chekpoint,'checkpoint.pth')\n",
    "state_dict = torch.load('checkpoint.pth')\n",
    "my_LR = Multi_LR_extended(\n",
    "    state_dict['input_size'],\n",
    "    state_dict['hidden_size_1'],\n",
    "    state_dict['hidden_size_2'],\n",
    "    state_dict['ouput_size'],\n",
    "    epochs=50,\n",
    "    lr=1e-3)\n",
    "my_LR.load_state_dict(state_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "homework_1.1._fchettouh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
